{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4주차 과제.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kim6419/-/blob/master/4%EC%A3%BC%EC%B0%A8_%EA%B3%BC%EC%A0%9C_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxkL6PjwsI6L",
        "colab_type": "text"
      },
      "source": [
        "# 4주차 과제\n",
        "- 용어 정리\n",
        "- 딥러닝 강의 클론 코딩\n",
        "- 딥러닝 순전파 & 역전파 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixEtDe6_uGgI",
        "colab_type": "text"
      },
      "source": [
        "## 1. 용어 정리\n",
        "\n",
        "다음 제시된 단어의 정의(설명)를 정리하여 작성 하세요.\n",
        "\n",
        "* 2문장 이상 작성 해 주세요. \n",
        "* 주제(단어)와 크게 벗어나지만 않는다면 정답처리 됩니다.\n",
        "* 강의 뿐 아니라 기타 레퍼런스를 참고하여 작성하셔도 됩니다. (기타 레퍼런스를 참고하신 경우, 해당 레퍼런스를 정리하여 하단에 작성해 주세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfwat8eurKZ",
        "colab_type": "text"
      },
      "source": [
        "__(예시)__\n",
        "### 심층 신경망\n",
        ": 입력층과 출력층 사이에 여러 개의 은닉층들로 이뤄진 인공신경망이다. 심층 신경망은 일반적으로 인공신경망과 마찬가지로 복잡한 비선형 관계들을 모델링 할 수 있다. 신층신경망의 목적은 분류 및 수치예측을 하기 위함이고 이미지 트레이닝이나 문자인식과 같은 분야에서 매우 유용하게 쓰이고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YJNKG_v65A",
        "colab_type": "text"
      },
      "source": [
        "### MCP 뉴런\n",
        ": \n",
        "뉴런들은 뇌의 신경세포와 서로 연결되어 있으며 화학적, 전기신호를 처리, 전달하는데 관여한다 맥컬록과 피츠는 이러한 신경세포를 이진 출력을 내는 간단한 논리회로로 표현했으며 그 후에 로젠블랫은 MCP뉴런 모델을 기반으로 퍼세트를 발표했다.\n",
        "\n",
        "부가 설명을 하자면\n",
        "AI를 설계하기 위해 생물학적 뇌가 동작하는 방식을 이해하려는 시도로, 1943년 워런 맥컬록(Warren McCulloch)과 월터 피츠(Walter Pitts)는 처음으로 간소화된 뇌의 뉴런 개념을 발표했다. 이를 맥컬록-피츠(MCP) 뉴런이라고 한다. \n",
        "\n",
        "### 퍼셉트론\n",
        ":퍼셉트론 규칙에서 로젠블라트는 자동으로 최적의 가중치를 학습하는 알고리즘을 제안 이 가중치는 뉴런의 출력 신호를 낼지말지를 결정하기 위해 입력 특성에 곱하는 계수가 된다. 이러한 퍼셉트론을 간단하게 표현하면 입력을 받아서 계산후 출력을 반환하는 구조로 나타낼 수 있다.\n",
        "\n",
        "퍼셉트론은 인공신경망의 한 종류로서, 1957년에 코넬 항공 연구소의 프랑크 로젠블라트 에 의해 고안되었다. 이것은 가장 간단한 형태의 피드포워드 네트워크 - 선형분류기- 로도 볼 수 있다. \n",
        "일단 Perceptron이라는 단어를 자세히 보면 퍼셉션과 뉴런, 이렇게 두 단어가 조합된 거라는 걸 알 수 있다.\n",
        "\n",
        "Perception : 무언가를 인지하는 능력\n",
        "Neuron : 감각 입력 정보를 의미있는 정보로 바꿔주는 뇌에 있는 신경 세포\n",
        "결국 퍼셉트론은 생물학적 뉴런이 감각 정보를 받아서 문제를 해결하는 원리를 따라한 인공 뉴런이라고 볼 수 있다.\n",
        "\n",
        "퍼셉트론을 하나만 보면 꽤 단순한 원리에 의해 결정을 내려준다.\n",
        "\n",
        "퍼셉트론의 구성요소\n",
        "(위에서 얼핏 언급하긴 했는데) 퍼셉트론은 세 가지 구성요소로 설명할 수 있다.\n",
        "\n",
        "1. Inputs\n",
        "인풋. 입력값. 뭐 흔히 머신러닝에서 말하는 feature(속성 혹은 자질)이다. 예를 들어 ‘사람’이라고 치면 키, 몸무게, 나이 같은 거.\n",
        "\n",
        "2. Weights\n",
        "가중치는 각 인풋에 대해 일정량의 중요도를 부여하는 개념이다. 예를 들어 어떤 인풋에 대해 가중치가 크다는 건 그 인풋이 아웃풋을 결정하는 데에 더 큰 역할을 한다는 뜻이다.\n",
        "\n",
        "3. Output\n",
        "퍼셉트론은 인풋과 가중치를 사용해서 아웃풋을 생성한다. 물론 아웃풋의 유형은 문제의 특성에 따라 조금씩 다르게 나타날 수 있다. 예를 들어 비가 올지 예측하려면 아웃풋이 2진(binary)일 거다. 1 아니면 0, 비가 오거나 안 오거나 둘 중 하나니까. 그런데 만약 다음 날의 온도를 예측하는 거라면 아웃풋의 범위가 커진다.\n",
        "\n",
        "퍼셉트론이 아웃풋을 내는 원리\n",
        "퍼셉트론은 인풋을 받으면 가중치에 따라 가중합(weighted sum)을 계산하고, 그 값이 특정 기준을 만족하면(activation function) 1, 아니면 0 으로 결과를 돌려주는 방식이다.\n",
        "\n",
        "\n",
        "### 역전파\n",
        ":역전파, 오차 역전파법 또는 오류 역전파 알고리즘은 다층 퍼셉트론 학습에 사용되는 통계적 기법을 의미한다. 기계 학습에서 사용되는 학습 구조로 다층 퍼셉트론이 있다. \n",
        "역전파 backpropagation\n",
        " 신경망의 역전파는, 그 이름에서도 알 수 있듯, 뉴런의 가중치를 효율적으로 조정하기 위하여, 거꾸로 무엇인가를 전파하는 방식이죠. \n",
        "\n",
        "순전파 & 역전파 \n",
        "\n",
        " 역전파 - 출력 값과 지도 데이터 사이에 생기는 ‘오차’를 이용해, 출력층에서 입력층 쪽으로 가중치를 조절하는 것. (역전파는 경사하강법을 사용하는 것이기도 하다.)\n",
        "\n",
        " 특정 입력값에서의 손실 함수값이 최소가 되더라도, 전체를 생각했을 때는 크게 의미가 없다.\n",
        " 궁극적으로 생각했을 때, 모든 입력값을 대상으로 손실함수가 최솟값일 때의 파라미터를 찾는 것이다. \n",
        " \n",
        "역전파를 때로는 ‘역방향 미분’이라고도 한다.\n",
        "\n",
        "*역전파 문제의 문제 \n",
        "\t역전파 기법에도 작은 문제가 있었으니, 바로 ‘기울기 소멸 문제’가 있다. \n",
        " 당시 역전파 알고리즘으로 학습을 진행 하는데 있어, 주로 사용된 활성화 함수는 시그모이드와 소프트맥스 였습니다.\n",
        " 우선 시그모이드의 경우 미분의 최대치가 0.3에 불과하며, 여러 층을 거칠수록 기울기는 점차 0에 수렴하게 되는 문제가 발생하였고, 소프트맥스는 출력 값으로 확률 벡터를 얻기 위해 사용됬었는데, 각 출력 노드의 출력 값을 0에서 1 사이의 값으로 제한하였다. \n",
        " \n",
        " 시그모이드나 소프트맥스는 최종 출력을 결정하는데 있어 합리적인 선택이 가능했으나, 출력된 값들이 항상 너무 작은 값을 가지고 있었기에, 신경망이 깊어지면 깊어질수록 오차의 기울기가 점차 작아지며, 끝으로 가는 도중 기울기가 소실돼버리면서 가중치 조정이 이뤄지지 않는다는 문제가 발생하게 됩니다. \n",
        " 이러한 기울기 소멸 문제를 해결하기 위해 제프리 힌튼 교수는 다양한 활성화 함수를 제시하였으며, 그 중 ReLU라는 활성화 함수를 활용하게 되면 어느정도 문제가 해결됨을 발견하였다.\n",
        " 이 활성화 함수는 입력이 음수일 때는 0을 출력하지만, 양수일 때는 양수 값을 그대로 출력하기에, 다른 활성화 함수보다 기울기 소실 문제에 있어, 어느정도 면역을 갖게 된다.\n",
        "\n",
        "\n",
        "### 강화학습\n",
        ":강화학습은 지도학습처럼 정답이 있지도 않고, 비지도 학습처럼 데이터만을 기반으로 학습하지도 않는다.\n",
        " 강화학습은 에이전트라는 존재가 환경과 상호작용하며, 이 환경에는 보상이라는 기준이 있어서 다양한 시행착오를 겪어가며 보상을 최대화하는 방향으로 학습을 진행한다. \n",
        "\n",
        " *강화학습의 학습과정\n",
        "간단한 예를 들어보자면, 우리가 자전거를 처음 탔던 날을 기억해보자.\n",
        "자전거는 처음이니, 여러 번 넘어지고 허벅지도 아프고 힘이 든다. >> ‘패널티’를 받는다.\n",
        "1~2시간쯤 지나서 넘어지지 않고 잘 달 리가 되었다. >> ‘보상’을 받는다.\n",
        "이렇게 여러번의 시도를 거쳐 점점 넘어지지 않게 학습하게 되고, 결국 우린 자연스럽게 자전거를 잘 타는 방법을 습득하게 된다. \n",
        "이것이 강화학습의 학습과정을 예로 든 것이다. \n",
        "\n",
        "강화학습은 이렇게 다양한 시행착오를 통해 학습이 가능하며, 비교적 명확한 보상을 설정할 수 있는데 사용되고 있다. 강화학습은 빠르게 발전을 거듭해 오면서 지금껏 인공지능으로 해결하기 힘들다고 생각한 많은 문제들을 해결해 왔다. \n",
        "도대체 강화학습은 어떻게 알고리즘에 의해 다치고, 넘어지며 때로는 뿌듯해 하는 걸까?\n",
        "강화학습을 한 문장으로 정리해보면, - “보상을 최대화하는 의사결정전략”\n",
        " 즉, “순차적인 행동들을 알아나가는 방법”입니다. \n",
        "\n",
        " 여기서 순차적으로 계속 행동을 결정해야하는 문제를 수학적으로 정의한 것이 그 유명한 \n",
        " \t(MDP) \"Markov Decision Process\"입니다. \n",
        "\n",
        "*MDP (Markov Decision Process)\n",
        " MDP는 상태, 행동, 보상함수, 상태 변환 확률, 감가율 이라는 구성요소들을 바탕으로 이루어져 있다.\n",
        "\n",
        "에이전트(Agent)  - 강화학습에서 의사결정을 하는 역할을 맡고 있다.\n",
        "\t예를 들어, 게임에서 우리가 조종하는 게임의 주인공이라고 생각하면 된다.\n",
        "\n",
        " 환경 -  에이전트의 의사결정을 반영하며, 에이전트에게 반영된 정보를 주는 역할을 \t\n",
        "\t담당한다. \n",
        "\n",
        "상태(State) - 에이전트는 상태라는 것을 기반으로 의사결정을 진행하게 된다. \n",
        "\t이 ‘상태’라는 요소는 의사결정을 하기 위해 사용되는 관측값, 행동, 보상을 가공한 \t정보라고 할 수 있다.\n",
        "\n",
        "행동(Action) - 에이전트가 의사결정을 통해 취할 수 있는 행동을 의미한다.\n",
        "\t일반적으로, 현재 상태에서 취하는 행동을 A(t)라고 정의한다. \n",
        "\t그리고 이 행동에는 ‘이산적인 행동’과 ‘연속적인 행동’ 이 있다. \n",
        "\t이러한 행동은 환경에 따라 정해지게 됩니다. \n",
        "\n",
        " \t-이산적인 행등을 하는 환경 : 에이전트에게 주어지는 행동의 선택지가 있으며, \t\t\t\t\t에이전트는 구 중 하나를 선택하게 된다.\n",
        "\n",
        "\t- 연속적인 행동을 하는 환경 : 선택지마다 특정 값을 수치로 입력하게 되고, \t\t\t\t\t\t에이전트는 입력된 값 만큼 행동하게 된다. \n",
        "\n",
        "\n",
        "관측(Observation) - 환경에서 제공해주는 정보.\n",
        "\t관측은 ‘시각적 관측’과 ‘수치적 관측’으로 구분되는데, \n",
        "\t\t-시각적 관측 : 현재 상태의 정보를 이미지로 표현한 것이며, \n",
        "\t\t-수치적 관측 : 이미지의 형태가 아닌, 수치로만 표현한 것.\n",
        "\n",
        "보상함수(Reward Function) - 에이전트가 특정 상태에서 특정 행동을 했을 때, \t\t\t보상을 받게 되고, 에이전트는 이 보상정보를 통해 학습을 진행하게 된다. \n",
        "\n",
        "* 강화학습은 마치 자전거를 배우기 위해 여러번 넘어지듯 ‘시행착오’라는 과정을 겪으며 보상을 최대화 하는 의사결정 전략을 학습하는 것이라 이야기 했다. \n",
        "그러면 이러한 의사결정은 어떻게 학습을 할 수 있는 것일까?\n",
        "강화학습은 에이전트가 지나왔던 상태에서 했던 행동에 대한 정보를 기록하게 된다. \n",
        "그리고 그 정보를 이용하여 그 다음 에피소드에 대한 의사결정을 하게 된다. \n",
        "그리고 또 에피소드가 끝나면 이 에피소드를 통해 얻게 된 정보로 기록을 업데이트 하며 이러한 과정을 반복하게 된다. \n",
        " \t\n",
        "그렇다면 어떠한 정보를 기록하게 됐을 때 좋은 의사결정을 내릴 수 있을까?\n",
        "\n",
        "- 에이전트는 더 나은 의사결정을 하기 위해 ‘현재 스텝에서 받았던 보상으로부터, 에피소드가 끝날 때까지 받았던 보상들을 더한 것을 정보로 이용’하게 됩니다.\n",
        " \n",
        "*감가율 \n",
        " 통상 그리스 문자 중 세 번째 감마를 활용하여 표기하며, \n",
        "0부터 1 사이의 값으로 설정, 1에 가까울수록 미래의 보상에 더 많은 가중치를 두게 된다.\n",
        "이제 감가율이 반영된 보상정보를 기록해 보면, 현재스텝에서 받았던 보상부터 에피소드가 끝날 때까지 받았던 보상들에 감가율을 스텝 차이만큼 곱해서 더해주게 된다.\n",
        "그리고 이 값을 ‘반환 값’이라고 부르게 된다. \n",
        "현재스텝에서의 ‘반환값’은 일반적으로 G라고 표기\n",
        "\n",
        "*반환값\n",
        " 반환값을 기록할 때는, 종료된 상태부터 처음 상태까지 거꾸로 계산하는게 좀 더 쉬우니, 역으로 계산을 진행해 보자.\n",
        " 환경에서의 보상은 목적지에 도착할 때만 얻기 때문에, 각 스텝의 반환 값은 이렇게 되며, 여기서 대문자 T는 에피소드가 종료된 스텝을 의미한다.\n",
        " 그리고 여기서 반환 값을 기록하게 되면, 에이전트는 이제 어느 경로가 효율적인지 판단할 수 있게 됩니다.\n",
        " 생각을 좀 더 해보면, 에이전트는 처음에 자신만의 길을 찾아 탐색을 진행 하였고, 이제 이 길은 에이전트가 모르는 길보다는 훨씬 더 괜찮다 판단할 수 있지 않을까?\n",
        " 사람도 마찬가지로, 새롭게 이사한 집을 찾아가기 위해, 찾아놓은 길로만 다니는 것처럼 말이다. \n",
        "그래서 가끔은, 에이전트에게 ‘무작위로 움직이게 설정’하여, 여러 경로를 시도해 보라는 \n",
        "‘탐험’(Exploration) 이라는 개념이 추가되게 된다.\n",
        "그리고 이 ‘탐험’과 대립되는 개념은 ‘이용’(Exploitation)이라는 개념으로, 에이전트가 찾아놓은 길로 하여 계속해서 선택하고 움직이게 되는 것을 의미한다. \n",
        "\n",
        "\n",
        "### 과적합\n",
        ":결정 트리 학습 (Decision tree) {나무 가지가 뻗쳐있는 것처럼 보인다.\n",
        "일련의 질문에 대한 결정을 통해 데이터를 분해하는 모델이다.\n",
        "이렇게 어떤 일을 할지 선택하기 위한 결정트리는 훈련 데이터에 있는 변수 즉 특성을 기반으로 새로운 샘플의 클레스 레이블을 추정할 수 있도록, 일련의 질문을 학습하게 된다. \n",
        "‘범주형 변수’, ‘실수형 변수’ 특성에서도 적용된다. 이 결정 알고리즘을 사용하면, 트리의 루트에서 시작해, 정보이득이란 값이 최대가 되는 특성으로 데이터를 나눕니다. \n",
        "리프 노드가 순수해질 때 까지 모든 자식 노드에서 이 분할작업을 반복한다. \n",
        "하지만 이와 같은 분할작업을 하다보면 깊은 트리가 만들어지게 되는데, 이는 곧 과적합을 불러일으킬 수 있죠. 그래서 일반적으로 트리의 최대 깊이를 제한하여 트리를 ‘가지치기’한다.\n",
        "\n",
        "목적함수의 목적\n",
        " 가장 정보가 풍부한 특성으로 노드를 나누기 위함\n",
        "\t트리 알고리즘으로 최적화.\n",
        " 이 목적함수는 각 분할에서 “정보 이득을 최대화”해야 한다는 임무를 가지고 있죠. \n",
        "\t(노트정리 참고)\n",
        "\n",
        "대부분의 라이브러리들은 구현을 간단하게 하고, 탐색 공간을 줄이기 위해 ‘이진 결정트리’를 사용하게 된다. \n",
        " 즉, 부모 노드를 두 개의 자식노드 (D left), (D right)로 나눠버린다는 말.\n",
        "\n",
        "이진 분류를 하기 위해서는 어떠한 분할 조건 혹은 불순도 지표를 사용해야 한다.\n",
        " *널리 사용되는 3가지 불순도 지표 혹은 분할조건\n",
        "\t(노트 참고)\n",
        " 1. 지니 불순도 (Gini ipurity) - 잘못 분류될 확률을 최소화 하기 위한 기준\n",
        " 2. 엔트로피 (entropy)\t- 트리의 상호 의존 정보를 최대화 하는 것\n",
        " 3. 분류 오차 (classification error) - 노드의 클래스 확률 변화에 둔감\n",
        "\n",
        "지니 불순도와 엔트로피 모두 매우 비슷한 결과를 나타냅니다.\n",
        " 그래서 지니 불순도나 엔트로피로 바꿔가며 트리 평가를 진행하기보다는\n",
        "가지치기 수준을 바꿔가며 튜닝하는 것이 권장된다.\n",
        "\n",
        " 이렇게 구한 계수들을 바탕으로 분할된 노드에서 다시 측정 분류 기준에 의해\n",
        "다시 자식 노드를 생성하고, 이를 바탕으로 또 다시 불순도를 구하며 가지를 뻗어 나갑니다.\n",
        " 그리고 최종적으로 불순도가 0에 수렴할때까지 즉, 하나의 클래스만을 가진 노드가 될 때까지 이를 반복해서 진행합니다.\n",
        " 무한으로 반복하다 보면 ‘과적합’을 불러 일으키기 때문에가지가 뻗어 내려가는 수준을 지정해줘야한다.\n",
        "\n",
        "\n",
        "\n",
        "### 차원의 저주\n",
        ": 차원의 저주 - 고정된 크기의 훈련 데이터셋 차원이 늘어남에 따라 특성 공간이 점점 희소해 지는 현상\n",
        " 또한 ‘차원의 저주’라는 훈련 데이터셋이 차원이 늘어남에 따라 특성 공간도 점점 희소해지는 현상을 피하기 위해, 올바른 변수의 선택, 차원 축소 기법 등을 사용해주면 된다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-zfFXLCy6jD",
        "colab_type": "text"
      },
      "source": [
        "## 2. 딥러닝 강의 클론 코딩\n",
        "\n",
        "####__퍼셉트론 구조 구현하기__ \n",
        "딥러닝 강의(__딥러닝 원리[1] 3:15 ~ 5:15 부분__)를 보고 코드를 따라 치며 출력 결과를 만드세요.\n",
        " \n",
        "\n",
        "* 하나의 코드셀에 해당 코드를 한번에 다 적어서 실행해주세요 (__그렇게 하지 않을 경우, 아래 이미지와 같은 출력값이 나오지 않을 수 있습니다__)\n",
        "\n",
        "*__주의!__ 실제로 코딩해서 출력해보면 강의에 나온 출력 결과와 다르게 나옵니다!!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcc5mzI9oZ7r",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0cceeed0-0235-4b0f-af88-0b8c377d5b4b%2F_2020-06-09__9.35.23.png?table=block&id=88fd8912-9356-49a4-9fda-a1a63fe96ea9&width=2870&cache=v2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1B0uu6cT67e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "ea8b88c8-baec-4c49-f049-879cd9fb576a"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(2020)\n",
        "x = 1\n",
        "y = 0\n",
        "w = tf.random.normal([1], 0, 1)\n",
        "\n",
        "import math\n",
        "def sigmoid(x) : \n",
        "  return 1/(1 + math.exp(-x) )\n",
        "\n",
        "output = sigmoid(x * w)\n",
        "print(output)\n",
        "\n",
        "for i in range(1000):\n",
        "  output = sigmoid(x*w)\n",
        "  error  = y - output\n",
        "  w = w + x * 0.1 * error\n",
        "\n",
        "  if i % 100 == 99:\n",
        "    print(\"학습횟수:\", i,\"Error:\", error, \"예측결과:\", output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.47477188589261\n",
            "학습횟수: 99 Error: -0.10010598284299604 예측결과: 0.10010598284299604\n",
            "학습횟수: 199 Error: -0.05178399422833116 예측결과: 0.05178399422833116\n",
            "학습횟수: 299 Error: -0.034590451977903586 예측결과: 0.034590451977903586\n",
            "학습횟수: 399 Error: -0.02588962752851373 예측결과: 0.02588962752851373\n",
            "학습횟수: 499 Error: -0.020658699939863617 예측결과: 0.020658699939863617\n",
            "학습횟수: 599 Error: -0.017174253993457355 예측결과: 0.017174253993457355\n",
            "학습횟수: 699 Error: -0.014689506449480992 예측결과: 0.014689506449480992\n",
            "학습횟수: 799 Error: -0.012829497265431342 예측결과: 0.012829497265431342\n",
            "학습횟수: 899 Error: -0.011385568271837804 예측결과: 0.011385568271837804\n",
            "학습횟수: 999 Error: -0.010232493309882492 예측결과: 0.010232493309882492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0HVRk8fOom",
        "colab_type": "text"
      },
      "source": [
        "## 3. 딥러닝 순전파 & 역전파 계산\n",
        "\n",
        "딥러닝 강의(__딥러닝 원리[2] 0:55 ~ 4:32 부분__)에 나오는 순전파 & 역전파 계산에 대한 문제 입니다.\n",
        "\n",
        "해당 영상과 다음 이미지를 참고하여 다음 2가지 물음에 답하세요.\n",
        "\n",
        "\n",
        "(1) 학습률이 0.2 일 경우 출력층의 노드값\n",
        "\n",
        "(2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpwPFWhOUzww",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff54dfd45-92ec-44ae-9616-6949d2484a45%2F_2020-06-10__5.22.03.png?table=block&id=ee05da89-3ceb-4ad9-a2d3-c9f68d24d1d9&width=3580&cache=v2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2OVY7w5U3CI",
        "colab_type": "text"
      },
      "source": [
        "## (1) 학습률이 0.2 일 경우 출력층의 노드값 : 1.6\n",
        "## (2) 학습률이 0.1과 0.2 중 기대출력값이 지도데이터 \"3\"과 더 가까운 학습률은? : 0.1"
      ]
    }
  ]
}